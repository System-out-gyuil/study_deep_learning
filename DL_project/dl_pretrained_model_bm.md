# ğŸš© Deep learning pretrained model project

## ë‚˜ë¹„ì™€ ë‚˜ë°© ì´ë¯¸ì§€ ë¶„ë¥˜

> https://www.kaggle.com/datasets/gpiosenka/butterfly-images40-species

### ëª©ì°¨

### 1. ë°ì´í„° í™•ì¸ ë° ì „ì²˜ë¦¬

- ë°ì´í„°ëŠ” ì´ 100ì¢…ì˜ ë‚˜ë¹„ì™€ ë‚˜ë°©ì´ ìˆìŠµë‹ˆë‹¤.

- ìœ ì‚¬ë„ê°€ ë†’ì€ ì‚¬ì „í›ˆë ¨ëª¨ë¸ì„ ì°¾ì•„ì„œ í•˜ë ¤ í•˜ì˜€ìœ¼ë‚˜ ë‚˜ë¹„ì™€ ë‚˜ë°©ì— ê´€ë ¨ëœ ì‚¬ì „ í›ˆë ¨ëª¨ë¸ì´ ì—†ë‹¤ê³  íŒë‹¨í•˜ì—¬ ë‚˜ë¹„ì™€ ë‚˜ë°©ì˜ ì´ë¯¸ì§€ê°€ ë³µì¡í•˜ë‹¤ íŒë‹¨í•˜ì—¬ Xceptionëª¨ë¸ìœ¼ë¡œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

- ë°ì´í„°ì˜ ê°¯ìˆ˜ê°€ ì•½ 14000ê°œì •ë„ë¼ì„œ ì´ˆê¸° ë°°ì¹˜ì‚¬ì´ì¦ˆë¥¼ 64ë¡œ ì„¤ì • í›„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.
  <details>
      <summary>ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì½”ë“œë³´ê¸°</summary>
      
        from tensorflow.keras.preprocessing.image import ImageDataGenerator

        IMAGE_SIZE = 112
        BATCH_SIZE = 64

        train_dir = './datasets/butterfly_moth/train'
        validation_dir = './datasets/butterfly_moth/valid'
        test_dir = './datasets/butterfly_moth/test'

        train_data_generator = ImageDataGenerator(rescale=1./255)
        validation_data_generator = ImageDataGenerator(rescale=1./255)
        test_data_generator = ImageDataGenerator(rescale=1./255)

        train_generator = train_data_generator.flow_from_directory(
            train_dir,
            target_size=(IMAGE_SIZE, IMAGE_SIZE),
            batch_size=BATCH_SIZE,
            class_mode='categorical'
        )

        validation_generator = validation_data_generator.flow_from_directory(
            validation_dir,
            target_size=(IMAGE_SIZE, IMAGE_SIZE),
            batch_size=BATCH_SIZE,
            class_mode='categorical'
        )

        test_generator = test_data_generator.flow_from_directory(
            test_dir,
            target_size=(IMAGE_SIZE, IMAGE_SIZE),
            batch_size=BATCH_SIZE,
            class_mode='categorical'
        )

  </details>

<br/>

- ì´ë¯¸ì§€ëŠ” ì•„ë˜ì™€ê°™ì´ ë‚˜ë¹„ì™€ ë‚˜ë°©ì´ í™”ë ¤í•˜ê³  ë…íŠ¹í•œ íŒ¨í„´ì´ ë§ì•„ì„œ ë³µì¡í•˜ë‹¤ê³  íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤.

  <img src="https://github.com/System-out-gyuil/study_data_analysis/assets/120631088/9fb72efd-f605-4d7d-a624-8e70574aa57d">

- ë§¤ì§ë©”ì†Œë“œ ì¬ì •ì˜ í›„ ë°ì´í„°ì…‹ì„ ë°˜í™˜í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

  <details>
    <summary>í´ë˜ìŠ¤ ì½”ë“œ ë³´ê¸°</summary>

        import numpy as np
        from tensorflow.keras.utils import Sequence
        from sklearn.utils import shuffle
        import cv2

        IMAGE_SIZE = 112
        BATCH_SIZE = 32

        class Dataset(Sequence):
            def __init__(self, file_paths, targets, batch_size=BATCH_SIZE, aug=None, preprocess=None, shuffle=False):
                self.file_paths = file_paths
                self.targets = targets
                self.batch_size = batch_size
                self.aug = aug
                self.preprocess = preprocess
                self.shuffle = shuffle

        if self.shuffle:
            # ì—í¬í¬ ì¢…ë£Œ ì‹œ, ê°ì²´ ìƒì„± ë° ë°ì´í„° ì„ê¸°
            self.on_epoch_end()

        # __len__()ëŠ” ì „ì²´ ë°ì´í„° ê±´ìˆ˜ì—ì„œ batch_size ë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë°ì´í„° ìˆ˜
        # ì˜ˆë¥¼ ë“¤ì–´, 1000ê°œì˜ ë°ì´í„°ë¥¼ 30 batch_sizeë¡œ ì„¤ì •í•˜ë©´, 1 batchë‹¹ 33.33..ê°œì´ë‹¤.
        # ì´ ë•Œ, ì†Œìˆ˜ì ì€ ë¬´ì¡°ê±´ ì˜¬ë ¤ì„œ 33 + 1 = 34ê°œë¡œ ì„¤ì •í•œë‹¤.
        def __len__(self):
            return int(np.ceil(len(self.targets) / self.batch_size))

        # batch_size ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ ë°°ì—´ê³¼ íƒ€ì¼“ ë°ì´í„°ë“¤ì„ ê°€ì ¸ì˜¨ ë’¤ ë³€í™˜í•œ ê°’ì„ ë¦¬í„´í•œë‹¤.
        def __getitem__(self, index):
            file_paths_batch = self.file_paths[index * self.batch_size: (index + 1) * self.batch_size]
            targets_batch = self.targets[index * self.batch_size: (index + 1) * self.batch_size]

            results_batch = np.zeros((file_paths_batch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))

            for i in range(file_paths_batch.shape[0]):
                image = cv2.cvtColor(cv2.imread(file_paths_batch[i]), cv2.COLOR_BGR2RGB)
                image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))

                if self.aug is not None:
                    image = self.aug(image=image)['image']

                if self.preprocess is not None:
                    image = self.preprocess(image)

                results_batch[i] = image

            return results_batch, targets_batch

        def on_epoch_end(self):
            if self.shuffle:
                self.file_paths, self.targets = shuffle(self.file_paths, self.targets)

  </details>

</br>

- ìœ„ì—ì„œ ì„ ì–¸í•œ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ train, test, validation ë°ì´í„°ì„¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤.

  <details>
    <summary>ë°ì´í„°ì…‹ ìƒì„± ì½”ë“œ ë³´ê¸°</summary>

        train_dataset = Dataset(train_file_paths,
                          train_targets,
                          batch_size=BATCH_SIZE,
                          preprocess=xception_preprocess_input,
                          shuffle=True)

        validation_dataset = Dataset(validation_file_paths,
                                validation_targets,
                                batch_size=BATCH_SIZE,
                                preprocess=xception_preprocess_input)

        test_dataset = Dataset(test_file_paths,
                                test_targets,
                                batch_size=BATCH_SIZE,
                                preprocess=xception_preprocess_input)

  </details>

</br>

### 2. ëª¨ë¸ ìƒì„± ë° ëª¨ë¸ í•™ìŠµ

- ì‚¬ì „í›ˆë ¨ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ë¶„ë¥˜ê¸°ë§Œ ì§ì ‘ ì‘ì„±í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë¥¼ í†µí•´ ëª¨ë¸ì„ ë§Œë“¤ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤.

  <details>
    <summary>ë°ì´í„°ì…‹ ìƒì„± ì½”ë“œ ë³´ê¸°</summary>

        def create_model(model_name='vgg16', verbose=False):
          input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))
          if model_name == 'vgg16':
              model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')
          elif model_name == 'resnet50': # ResNet50, 74.9% ; ResNet50V2, 76.0%
              model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')
          elif model_name == 'xception': # Inceptionì„ ê¸°ì´ˆë¡œ í•œ ëª¨ë¸
              model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')
          elif model_name == 'mobilenet':
              model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')

          x = model.output

          # ë¶„ë¥˜ê¸°
          x = GlobalAveragePooling2D()(x)
          if model_name != 'vgg16':
              x = Dropout(rate=0.5)(x)
          x = Dense(50, activation='relu')(x)
          if model_name != 'vgg16':
              x = Dropout(rate=0.5)(x)
          output = Dense(100, activation='softmax', name='output')(x)

          model = Model(inputs=input_tensor, outputs=output)

          if verbose:
              model.summary()

          return model

        model = create_model(model_name='xception', verbose=True)
        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])

  </details>

</br>

- í•´ë‹¹ ëª¨ë¸ë¡œ í•™ìŠµ ì§„í–‰ ê²°ê³¼

  <img src="https://github.com/System-out-gyuil/study_data_analysis/assets/120631088/e12aa6e6-4073-435c-96b5-ba93a4c53a13">

  - êµ‰ì¥íˆ ì–‘í˜¸í•œ ê²°ê³¼ê°€ ë‚˜íƒ€ë‚˜ì„œ ë”ì´ìƒ ê±´ë“¤ í•„ìš” ì—†ë‹¤ê³  íŒë‹¨í•˜ì˜€ê³ , í•œ ì—í¬í¬ë‹¹ 11ë¶„ì—ì„œ 12ë¶„ì”© ê±¸ë¦¬ê¸°ë•Œë¬¸ì— ì‹œê°„ ë‹¨ì¶•ì„ ìœ„í•´ ë¯¸ì„¸ì¡°ì •ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

### 3. ë¯¸ì„¸ ì¡°ì •

- í•´ë‹¹ ëª¨ë¸ê³¼ ë°ì´í„°ëŠ” ìœ ì‚¬ë„ê°€ ë‚®ë‹¤ê³  íŒë‹¨ë˜ì§€ë§Œ ì‹œê°„ ë‹¨ì¶•ë§Œ í•´ë³¸ë‹¤ëŠ” ìƒê°ìœ¼ë¡œ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.

- ìœ ì‚¬ë„ê°€ ë‚®ê¸°ë•Œë¬¸ì— ìµœìƒìœ„ ì¸µë§Œ ì¡°ê¸ˆ freezeí•˜ì˜€ìŠµë‹ˆë‹¤.

  <details>
    <summary>ë¯¸ì„¸ì¡°ì • ì½”ë“œ ë³´ê¸°</summary>

        def fine_tune(datas, model_name, preprocess):
        FIRST_EPOCHS = 10
        SECOND_EPOCHS = 10

        train_file_paths, train_targets, \
        validation_file_paths, validation_targets, \
        test_file_paths, test_targets = datas

        train_dataset = Dataset(train_file_paths,
                            train_targets,
                            batch_size=BATCH_SIZE,
                            preprocess=preprocess,
                            shuffle=True)

        validation_dataset = Dataset(validation_file_paths,
                                validation_targets,
                                batch_size=BATCH_SIZE,
                                preprocess=preprocess)

        model = create_model(model_name=model_name, verbose=True)
        model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['acc'])

        # feature extractor layerë“¤ì„ ì „ë¶€ freeze
        for layer in model.layers[:-5]:
            layer.trainable = False

        model.fit(train_dataset,
                  batch_size=BATCH_SIZE,
                  epochs=FIRST_EPOCHS,
                  validation_data=validation_dataset)

        # ë°°ì¹˜ ì •ê·œí™”ë§Œ freeze ì§„í–‰
        for layer in model.layers:
            if not isinstance(layer, layers.BatchNormalization):
                layer.trainable = True

        # ë¶€ë¶„ freeze ì§„í–‰
        for layer in model.layers[:14]:
            layer.trainable = False

        model.compile(optimizer=Adam(0.00001), loss=CategoricalCrossentropy(), metrics=['acc'])
        history = model.fit(train_dataset,
                  batch_size=BATCH_SIZE,
                  epochs=SECOND_EPOCHS,
                  validation_data=validation_dataset)

        return model, history

        model, history = fine_tune((train_file_paths, train_targets,
           validation_file_paths, validation_targets,
           test_file_paths, test_targets),
          'xception',
          xception_preprocess_input)

  </details>

</br>

- ëª¨ë¸ í›ˆë ¨ ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

  <img src="https://github.com/System-out-gyuil/study_data_analysis/assets/120631088/7c5eab7c-f0eb-49ec-ad98-ee5f99717110">

- í™•ì‹¤íˆ ê¸°ì¡´ Xception ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ì„ë•Œë³´ë‹¤ ì†Œìš”ì‹œê°„ì´ ë§ì´ ì¤„ì–´ë“  ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤.
- ì •í™•ë„ê°€ 0.6ì •ë„ë¡œ ë§ì´ ë‚®ì•„ì¡ŒìŠµë‹ˆë‹¤.
- í•˜ì§€ë§Œ ê²€ì¦ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì •í™•ë„ ë˜í•œ 0.8~0.9 ì •ë„ë¡œ ì¡°ê¸ˆ ë‚´ë ¤ê°„ ëª¨ìŠµì„ ë³´ì…ë‹ˆë‹¤.

### 4. ëª¨ë¸ í‰ê°€

- ê²€ì¦ê³¼ í…ŒìŠ¤íŠ¸ë°ì´í„°ì˜ ì •í™•ë„ê°€ ë†’ì•„ì„œ ì„±ëŠ¥ì„ í‰ê°€í•´ë³´ê¸° ìœ„í•´ ì§ì ‘ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì„œ ì˜ˆì¸¡í•´ë³¸ ê²°ê³¼

  <img src="https://github.com/System-out-gyuil/study_data_analysis/assets/120631088/12155918-abb4-488a-b0a0-ff685e92dc5c">

  - ìŠ¤ë¬´ê°œì˜ ì´ë¯¸ì§€ ì¤‘ ë‘ê°œë¥¼ ì œì™¸í•˜ê³  ëª¨ë‘ ë§ì¶˜ ëª¨ìŠµì„ ë³´ì´ë©° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### 5. ëŠë‚€ì 

- ì‚¬ì „ í›ˆë ¨ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì•„ì£¼ ë›°ì–´ë‚˜ë‹¤ëŠ”ê²ƒì„ í™•ì‹¤í•˜ê²Œ ëŠê¼ˆìœ¼ë©°, ë‚˜ë¹„ì™€ ë‚˜ë°©ì— ìœ ì‚¬ë„ê°€ ì—†ëŠ” Xception ëª¨ë¸ì„ ì‚¬ìš©í•˜ì˜€ìŒì—ë„ ì•„ì£¼ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.